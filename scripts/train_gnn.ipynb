{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ae5cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\")) \n",
    "sys.path.append(os.path.join(ROOT, \"src\"))\n",
    "import matplotlib.pyplot as plt \n",
    "from dagc.sparsifiers.gnn.train import train_gnn_sparsifier_on_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6882f185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Using device: cpu\n",
      "[train] Loaded 120 train graphs and 40 val graphs\n",
      "[Epoch 1/10] train_loss = 0.086810 (rw=0.0000, sparse=0.0434) val_loss = 0.080000 (rw=0.0000, sparse=0.0400)\n",
      "[Epoch 2/10] train_loss = 0.080000 (rw=0.0000, sparse=0.0400) val_loss = 0.080000 (rw=0.0000, sparse=0.0400)\n",
      "[Epoch 3/10] train_loss = 0.080000 (rw=0.0000, sparse=0.0400) val_loss = 0.080000 (rw=0.0000, sparse=0.0400)\n",
      "[Epoch 4/10] train_loss = 0.080000 (rw=0.0000, sparse=0.0400) val_loss = 0.080000 (rw=0.0000, sparse=0.0400)\n",
      "[Epoch 5/10] train_loss = 0.080000 (rw=0.0000, sparse=0.0400) val_loss = 0.080000 (rw=0.0000, sparse=0.0400)\n",
      "[Epoch 6/10] train_loss = 0.080000 (rw=0.0000, sparse=0.0400) val_loss = 0.080000 (rw=0.0000, sparse=0.0400)\n",
      "[Epoch 7/10] train_loss = 0.080000 (rw=0.0000, sparse=0.0400) val_loss = 0.080000 (rw=0.0000, sparse=0.0400)\n",
      "[Epoch 8/10] train_loss = 0.080000 (rw=0.0000, sparse=0.0400) val_loss = 0.080000 (rw=0.0000, sparse=0.0400)\n",
      "[Epoch 9/10] train_loss = 0.080000 (rw=0.0000, sparse=0.0400) val_loss = 0.080000 (rw=0.0000, sparse=0.0400)\n",
      "[Epoch 10/10] train_loss = 0.080000 (rw=0.0000, sparse=0.0400) val_loss = 0.080000 (rw=0.0000, sparse=0.0400)\n",
      "[train] Restoring best model with val_loss = 0.080000\n",
      "[train] Saved checkpoint to: results/checkpoints/gnn_rw_k1_keep0.8_num_steps_1.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAHHCAYAAABEEKc/AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAATuRJREFUeJzt3Ql8VNX1wPGTfWGHQNgJWwXKJjvYghZkERcsKiIWRCqlAoJU/gVkUQFRy6aA0lhFKVIQK5RSxAJSUAGRTcSyFAHZDCQEErKHZP6fc2HGmWESkpBktt/38xkz896dNy9vBufk3HPvDbBYLBYBAACATeBPdwEAAECABAAA4AIZJAAAACcESAAAAE4IkAAAAJwQIAEAADghQAIAAHBCgAQAAOCEAAkAAMAJARIAj/PCCy9IQEBAib/Of/7zH/M6+hO++zlKSEhw96nACxEgAU7ee+898z9V6y04OFhq1aolTzzxhJw9e9bW7sMPPzT7V69efcM1bNWqldm3ZcuWG/bVrVtXunTpwnUvpJdfflnWrFnDdQNQKgiQgDy89NJL8te//lUWL14sffr0kWXLlkm3bt0kIyPD7P/FL35hfn7xxRcOz0tOTpaDBw+awOrLL7902Hf69Glzsz4Xrk2ePFnS09MdthEgAShNBEhAHjQoevzxx+W3v/2t/OUvf5HnnntOvv/+e1m7dq3ZX7NmTalfv/4NAdKOHTtE14B++OGHb9hnfVyUAEkzUprd8lYaWObm5haorQaX4eHhJX5OuLnU1FQuE/wSARJQQL/85S/NTw2SrDTQ2bdvn0O2Q7NGP//5z02AtXPnToegQPdpoHPHHXeU2nWPi4uToUOHSu3atSUsLExq1KghDzzwgJw8edLWJiYmRu69917597//La1btzbBSbNmzeTjjz92OFZiYqIJFFu0aCFly5aV8uXLm9/zm2++cVnbs2LFCpMN0i7KyMhIk13Lzs6WF198URo3bmxep0qVKuY6bty4Mc8aJL2vX9Tvv/++retTuzy1CzOvbs7ly5ebfRqwFtaqVaukbdu2EhERIVFRUSZQtu9eLeh13b17t/Tq1cscQ4+lAfWTTz5ZoHN48803zedIj63B+MiRI+Xy5cu2/aNGjTLvQVpa2g3PHThwoFSvXl1ycnJs2z755BPzGS5TpoyUK1dO+vbtK999953D8/Sa6jH1M37PPfeYdoMGDcr3PPW66O8UHR1tzlXP+d1333X5eVi5cqVMmjTJnJuex/33328yqkW5/urw4cPyyCOPSNWqVU3b2267TZ5//vkb2ul109+tYsWKUqFCBfO+OV83/fzp51Db6DXQY+m5wn8Fu/sEAG9h/eKrVKmSbZv+D1W74b766iu58847bUGQ1hjpLSkpyXS3tWzZ0ravSZMmJigoLf379zdfhKNHjzaB0IULF8yXwalTp8xjq//9738yYMAAGTFihAwZMkSWLFlismAbNmyQu+++27Q5fvy4qQPS7fplf/78efnzn/9suh7/+9//mi9ye9OnT5fQ0FATVGVmZpr7GvzMmjXLZOY6dOhggiYNJPbu3Wt7HWd6ja3thw8fbrY1bNhQOnXqJHXq1JEPPvhAHnzwQYfn6DZt07lz50JdL83S6Rdo+/btzXnq7/j666+b906DYf0CLch11cc9e/Y0X94TJkwwz9PPkHPQ6YpeIw0ie/ToIb///e/lyJEj8tZbb8nXX39tziMkJMS8V4sWLZJ//etf5v2w0i/+f/7znyYgCAoKsl0/fU81WHv11VdNGz2eNcC3/xxcvXrVtNN9s2fPNoFtXvTa6HugwY8GbPq7aiA2bNgw876OHTvWof3MmTNN2z/+8Y/m+syfP9/8jvv37zcBTmGu/4EDB0zAp9dCPxP6O2hgp7+7vo49DaL086rH08+ZZoSrVatmroXS91H/QNB/p9q1roHesWPHbugih5+xAHCwZMkSi/7T2LRpkyU+Pt5y+vRpy0cffWSpWrWqJSwszDy2+u6770zb6dOnm8fZ2dmWMmXKWN5//33zODo62rJo0SJzPzk52RIUFGR56qmninTF9XX03Arj0qVL5nl/+tOf8m1Xr1490+7vf/+7bVtSUpKlRo0alttvv922LSMjw5KTk+Pw3BMnTpjr8tJLL9m2bdmyxRyvQYMGlrS0NIf2rVq1svTt2zff85k2bZp5vj29rkOGDLmh7cSJE83rX7582bbtwoULluDgYHOc/FjPU3+qrKwsS7Vq1SzNmze3pKen29qtW7fOtJs6dWqBr+vq1atNm6+//tpSGHruoaGhlp49ezpc64ULF5rjvfvuu+Zxbm6upVatWpb+/fs7PP/DDz807bZt22YeX7lyxVKxYsUbPndxcXGWChUqOGzX66vPnTBhQoHOddiwYeYzkpCQ4LD90UcfNce2vvfW66znq/8OnM/19ddfL9T1V127drWUK1fO8sMPPzi8tl4X58/Rk08+6dDmwQcftFSpUsX2eN68eaad/nsHrOhiA/Kgf9nqX8SaoXjooYdMl4DWH2mXilXTpk1NNshaW6RdTdoVZB2lpj+tf4VqV492eRSk/kj/wtehyfY3lZKS4rDt0qVL+R5H/yrXrI12cdysrWZ/7LMw2n02ePBg81e7dicp/cs6MPDa/zb0d7l48aKtO0L/MnemWQtrZsBKMwD6F7tmrIqDnqNmpz766CPbNu3K0UyIds0UhmayNLPx9NNPO9RAaXeUZv40W1PQ62rNdKxbt850KxbUpk2bJCsry2RfrNdaPfXUU+Y9sZ6DZmI0c7R+/XrzubD/3bVL0/o506yWdjFpt5v9Z0ezSx07dnQ50lKzVjejMfvf//53ue+++8x9+2NrBkqzp86fCX2vtNvOSv9dadek/g6Fuf7x8fGybds207Wno0LtuZoeQrOi9jTzpJ9dzXLZv1f/+Mc/ClwnB99HgATkQbsv9MtFv3i1HkP/x68BgvP/jDUIstYaaTCkqftGjRrdECBZfxYkQHrttddMcGZ/U9qdY7/t9ttvz/c4er7ajaDdHloj0rVrV3Nsa8BjT8/Z+cvlZz/7mUP3ov6O8+bNM/VDemytD9Hz0O4O/UJ0pt0azrQLQ7+w9dhayzR+/Hjz/KLSL07tjtEuNSu9r10/1vehoH744QfzUwM+V69j3V+Q66rdjtoNp11lep20Pkm7LTWYK8o5aEDWoEED236l3Wxa/2YdOKCBkgYbGjhZ30trIPqrX/3qhs+U1pxpQOJcIG//R0BeNEjR9zE2NvaG42oXmXI+tn5u7Ok56ntk/XwV9PprV69q3ry5FIRzEGXtJrcGt3odtS5Qu3H1/Xz00UfNNB4ES/6NGiQgD1rv0q5dO3O/X79+JrB57LHHTD2IZk2sdLvWPXz77be2+iMrva8BgBaYapZJszT6JXcz+pe2cyCl9Tl6LK1rsXLOzriimQj9K19rhz799FOZMmWKqcX47LPPbhpgOdOh9vp8/ctd64sqV65sshz6Gq6+TFydnwYTWiuif63rF7TWg2jQpdMp6BdUUej1GjNmjJw5c8YEIBqwLly4UErSza6rfvlrcK3nop8PbaPXbc6cOWab/WeoqDQI1Nob/TLXz6a+jgZM+oVvZX1ftA5Ji6OdaUBkzz5LmB/rcTVLp5lCV6y1d+5mrcVydq3n+trnVDNSmk3TLJXW3WkmToNK/Yzm9Xz4OFtnGwCHGiTn2hFrHcWsWbMctn/55Zdmu9aIaI2FfV2K1uxofcyyZctMDc3DDz9c5KtclBokV44ePWqJjIy0DBo0yKEGqWbNmg71G+qPf/yjed0ff/zRVj9011133XBM/b27det2w7VatWrVTc9Ha2S0zkmPkV8NUtmyZV3WICmtHQkJCbG89tprlhdffNHcL0g9iXMN0vbt283jN99884a2TZs2tbRt27ZQ19XZBx98YI7/9ttv59lm+fLlps369esdtmdmZpq6Hueao//7v/8znzGtGXvggQcsMTExDvutdT6ffvqp5Wb0+urntCCuXr1qaoAGDhxY4Ous9WL29POmNUy9evUq1PXXOi1tN2bMmHxf1/o5cv4sWP+Na/1cXmbOnGnabNy48aa/H3wTXWxAAekoNc0q6cgb62SRSrNMWi+h3TqaKbLPIOlf423atDHddVqbVNoTRGotk/25Kh3ZpXUgzl09586dcxgur/UZS5cuNcP+rZkH/Uva+le3/ZBsV0Ow86K1H/Y0k6LdLDfretIaMPth7va0C8s6mae+D7179zbbCkvfS+0i1WyW/floV9qhQ4dMLUxBr6t23zhfK72WKr/fVWvftDvtjTfecHj+O++8Y7oxredgpdkiPZ5OgaCZDx2xZU/rgbR2SbN/rmqhtKusKPSzoF2IWoekIzULclz9PF25csX2WDNsP/74o3nvCnP9tRtPM5E6nYCOGrTnfM0LQqevcFaQ9wq+jS42oBC0i0vrO3QosrXwU7/MtAbm888/NwGRzt9iTwMm7VZRpR0gHT16VLp3726+NHVeI+1O0SBIh05rnYU9rQnS4dk6lFzrMPTLR9tp3YyVDoXWGiKtMdHfS7sVNSApSLehlZ6HBpt6nbSLTgtz9YtSh4nnR9trAfPcuXNtk3RqkbF9N5sW/Srt/isKHTKutUX6+2kNkRY2W4eZa1fWs88+W+DrqgGLzmWkhe8aPGlg8Pbbb5tgRWva8qJf/hMnTjS1Sxro6VxB2q2rx9LPmXPhuQbgGmDq/D/6ZW7fvab09XRI/29+8xvTVs9PX0MDC+1O0tqbonZHvvLKK6ZbSt8HLSLXa6HBhhZn63vlHHjo+63/BvT66rXSPzb03PW5hbn+SgNIPZb+TjrMXz8PWsukv5NOG1AY+pnWLjYNwOrVq2dqp/R6ay0Ws977MXensABv6WJTOuy6YcOG5qZdDFbadaDP6dKlyw3P+fjjj80+7Y6wf05pdLHp8OuRI0damjRpYrpOtIumY8eOptvFnnax6dB77YZp2bKl6bLR5zh3kWmX4R/+8AfTLRIREWG54447LDt27DDdawXtYpsxY4alQ4cOZui5HkNfR7szdIh3fl1shw8fNkO79Tm6z7m7TbugKlWqZH5H+yHihelis1q5cqXp9tPrULlyZdNtdubMmUJd171795rup7p165rj6PD1e++917J79+4CnZt22erxtbtQp4v4/e9/b6YXcOX55583v0ejRo3y/V21K0vPNTw83HyGn3jiCYfzKUwXm9X58+fNtahTp4451+rVq1u6d+9uiY2NdXhtPb+//e1v5t+KXgt9H/Uz5zxMvyDX3+rgwYNmyL5+lvR3uu222yxTpkwpdBfb5s2bTfekdjPrFAv6U9877TaF/wrQ/7g7SAPgXvrXuY4I0iHp3kqH9WtmSQuntTsKnkOnQ7jrrrtMd6w1ywd4OmqQAPgEHU2mdS/a1QYAt4oaJABeTZd50XmUtO5Ih9dr7QoA3CoySAC8mhYg68zPOvpJR0kBQHGgBgkAAMAJGSQAAAAnBEgAAABOKNIuIl2HSGce1plzXa0eDQAAPI/ObqQTt+q0IPmtO0iAVEQaHNWpU6eoTwcAAG50+vRpM1t6XgiQikgzR9YLrFP5AwAAz6frTGqCw/o9nhcCpCKydqtpcESABACAd7lZeYxHFGnrSue61IGuiK6LHu7atSvf9jpdfZMmTUz7Fi1ayPr16x32p6SkmIUvNXUWERFhFlDU1aGtdEFDvTCubnpsAADg39weIK1cuVLGjRsn06ZNMytAt2rVSnr16mVWU3Zl+/btZoVnXXV837590q9fP3M7ePCgrY0eb8OGDbJs2TI5dOiQjB071gRMa9euNfs1tfbjjz863HTl7LJly0qfPn1K7XcHAACeye0TRWrGqH379rJw4ULb6DANYEaPHi0TJky4of2AAQMkNTXVYVHNTp06SevWrW1ZIl10U9tNmTLF1qZt27Ym+JkxY4bL89AlCtq0aVPgRS61D7NChQqSlJREFxsAAF6ioN/fbq1BysrKkj179sjEiRNt23TIXY8ePWTHjh0un6PbNUNkTzNOulClVZcuXUy26MknnzTD+HQl6aNHj8q8efNcHlPPYf/+/aarDwAAd8vJyZHs7Gx3n4ZXCgkJkaCgoFs+jlsDpISEBPMhiI6Odtiujw8fPuzyOXFxcS7b63arBQsWyPDhw00NUnBwsAm63n77benatavLY2rWqGnTpiawyktmZqa52UegAAAUJ+3U0e+zy5cvc2FvQcWKFaV69eq3NE+hT45i0wBp586dJotUr1492bZtm4wcOdJkkzQ7ZS89PV2WL1/u0B3nyqxZs0ydEgAAJcUaHOniy5GRkUxEXIQAMy0tzVbHXKNGDfHKACkqKsqkwc6fP++wXR9r5OeKbs+vvQY8kyZNktWrV0vfvn3NtpYtW5outNmzZ98QIH300UfmYg4ePDjfc9VuQPuuPes8CgAAFAftUbEGR1WqVOGiFpGOXlcaJOm1LGp3m1tHsYWGhpri6c2bN9u2aZG2Pu7cubPL5+h2+/Zq48aNtvbaZ6s35+nD9QLpsV11r91///1StWrVfM81LCzMNucRcx8BAIqbteZIM0e4NdZreCt1XG7vYtOszJAhQ6Rdu3bSoUMHmT9/vhmlNnToULNfMzu1atUyXVxqzJgx0q1bN5kzZ47JEK1YsUJ2794tsbGxZr8GL7p//PjxJorULratW7fK0qVLZe7cuQ6vfezYMdP95jyPEgAA7sL6np5xDd0eIOlw/Pj4eJk6darpe9Xh+jqHkbUQ+9SpUw7ZIC2k1pqhyZMnm660xo0bmxFsOrTfSoMm7RIbNGiQJCYmmiBp5syZMmLECIfXfvfdd00hd8+ePUvxNwYAAJ7O7fMgeSvmQQIAFKeMjAw5ceKE1K9f36wU4a9iYmLMBM96K4lr6RXzIAEAAO935513mh4gLZO5VV9//bWUKVNG3I0AycNczcmVM5fSpVx4sFQpG+bu0wEA4JZpZ5WO0tO5CW/mZoOm/GYtNjgas3K/3Dn7P7Jm/zkuDQDA4z3xxBNmMNTrr79uW/j9vffeMz8/+eQTM1pdR4J/8cUX8v3338sDDzxg6ox1/VNdamzTpk03dLHZZ6L0OH/5y1/kwQcfNKPTtPbYurZqSSJA8jAxVa4NTTyRkOLuUwEAeMLEh1lX3XKzFLBEWQMjnWrnqaeesi0Ab50nUNdUfeWVV8zC8TonYUpKitxzzz1muh5dcL53795y3333mQFZ+dGJmh955BE5cOCAeb51EFZJoovNw9SPKmt+nkhIdfepAADcLD07R5pN/dQtr/3fl3pJZOjNwwQteNZ5DTW7Y5202bpc2EsvvSR33323rW3lypWlVatWtsfTp083EztrRmjUqFH5ZqkGDhxo7r/88svyxhtvyK5du0yAVVLIIHmY+lHXCtNOxBMgAQC8W7t27RweawbpueeeM+uf6npp2s2m2aWbZZA0+2SlBdw6+sy6nEhJIYPkYRpcD5DOJWVIelaORITe+orEAADvFBESZDI57nrtW+U8Gk2DI139Qpf+atSokZnQ+aGHHpKsrKx8jxMSEuLwWOuSXK2OUZwIkDxMpTKhUikyRC6lZZtutmY1856jAQDg2zQQKEg3l7uFhoaaUWo38+WXX5ruMi24tmaUTp48KZ6ILjZP7majDgkA4AViYmLkq6++MsFOQkJCntkdHYH28ccfmwXkv/nmG3nsscdKPBNUVARIHl2ozUg2AIDne+6558yi8M2aNTPzGOVVU6RrolaqVMksG6aj13r16iVt2rQp9fMtCM/P2/mhBlWvZZCOk0ECAHiBn/3sZ7Jjxw6HbdqV5irT9NlnnzlsGzlypMNj5y43V9MNXL58WUoaGSQPRBcbAADuRYDkgQiQAABwLwIkDw6QLqdlS2Jq/kMfAQBA8SNA8kDhIUFSq2KEuU+hNgAApY8AycOzSMeZURsAgFJHgOShqEMCAMB9CJA8FAESAADuQ4DkoepfnwuJ2bQBACh9BEgeqqFtNu1Uyc29cZIsAABQcgiQPFStShESEhQgmVdz5VxSurtPBwCAEqMzbM+fP188CQGShwoKDJB6VehmAwDAHQiQPBiF2gAAuAcBkgdrwFxIAAAPFxsbKzVr1pTc3FyH7Q888IA8+eST8v3335v70dHRUrZsWWnfvr1s2rRJPB0BkgcjgwQAfk5Xss9Kdc/NUrABQg8//LBcvHhRtmzZYtuWmJgoGzZskEGDBklKSorcc889snnzZtm3b5/07t1b7rvvPjl16pR4smB3nwDy1qDqtZFsxxNSuEwA4I+y00Rerume1550TiT0Wi1sfipVqiR9+vSR5cuXS/fu3c22jz76SKKiouSuu+6SwMBAadWqla399OnTZfXq1bJ27VoZNWqUeCoySF6QQTpzKV0yr+a4+3QAAHBJM0V///vfJTMz0zz+4IMP5NFHHzXBkWaQnnvuOWnatKlUrFjRdLMdOnSIDBKKLqpsqJQLC5YrmVfl1MU0aRxdjssJAP4kJPJaJsddr11A2mVmsVjkX//6l6kx+vzzz2XevHlmnwZHGzdulNmzZ0ujRo0kIiJCHnroIcnKyhJPRhebBwsICDAzah84kyTHE1IJkADA3wQEFKiby93Cw8Pl17/+tckcHTt2TG677TZp06aN2ffll1/KE088IQ8++KB5rBmlkydPiqcjQPKCbjYNkFhyBADg6d1s9957r3z33Xfy+OOP27Y3btxYPv74Y5Nl0j/8p0yZcsOIN09EDZKHa2BdciQ+1d2nAgBAnn71q19J5cqV5ciRI/LYY4/Zts+dO9cUcnfp0sUESb169bJllzwZGSQvWbSWkWwAAE8WGBgo586dc7mMyGeffeawbeTIkQ6PPbHLjQySl0wWSRcbAAClhwDJw8VcD5ASUrIkKT3b3acDAIBfIEDycGXDgqVauTBz/2QCdUgAAJQGAiQvwJIjAACULgIkr1pyhAwSAPg6nXAR7r+GBEheVKh9PJ412QDAV4WEhJifaWlp7j4Vr2e9htZrWhQM8/cCdLEBgO8LCgoya5VduHDBPI6MjDQTK6JwmSMNjvQa6rXUa+q1AdKiRYvkT3/6k8TFxZnVfhcsWCAdOnTIs/2qVavMLJw6Z4LOzvnqq6/KPffcY9uvU5hPmDBB1qxZIxcvXpT69evLM888IyNGjHA4zo4dO+T555+Xr776ylzA1q1by6effmrWiPHUuZB0qL+++fyDAQDfVL16dfPTGiShaDQ4sl5LrwyQVq5cKePGjZPFixdLx44dZf78+WaGTZ2Fs1q1aje03759uwwcOFBmzZplpjNfvny59OvXT/bu3SvNmzc3bfR4OiHVsmXLzORU//73v+Xpp5+WmjVryv33328Ljnr37i0TJ040AVlwcLB88803ZpIrT1SnUqQEBQZIWlaOXLiSKdHlw919SgCAEqB/ANeoUcN8B2ZnM7VLUWi32q1kjqwCLG6sBtOgSFf9XbhwoXmsa7PUqVNHRo8ebbJAzgYMGCCpqamybt0627ZOnTqZ7I8GWUoDJW2nWSartm3bSp8+fWTGjBm259x9990yffr0Ip97cnKyVKhQQZKSkqR8+fJS0u780xY5eTFN/vZUJ+ncsEqJvx4AAL6ooN/fbkuZZGVlyZ49e6RHjx4/nUxgoHmsGR5XdLt9e6UZJ/v2utbL2rVr5ezZs6Y7asuWLXL06FHp2bOnLW2p3WoanWvb6Oho6datm3zxxRf5nm9mZqa5qPY394xko1AbAICS5rYAKSEhQXJyckyAYk8faz2SK7r9Zu21y6xZs2ZSu3ZtCQ0NNV1pWufUtWtXs//48ePm5wsvvCBPPfWUbNiwwSya1717d/nf//6X5/lqt55GnNabZrrcUqjNorUAAJQ4zyy6uQUaIO3cudNkkTRDNWfOHLMo3qZNm2zdeOp3v/udDB06VG6//XaZN2+e3HbbbfLuu+/meVytV9J0nPV2+vRpKU2MZAMAoPS4rUg7KirKFFGdP3/eYbs+zqvyXLfn1z49PV0mTZokq1evlr59+5ptLVu2lP3798vs2bNN95wWvynNMtlr2rSpnDp1Ks/zDQsLMzd3YdFaAAD8IIOk3V9aPL1582bbNs3u6OPOnTu7fI5ut2+vNm7caGuvFf96cx6NpoGYNXOkI9t0RJuOlLOndUr16tUTT2Ud6n8qMU2yc679LgAAoGS4dZi/DskfMmSItGvXzsx9pMP8dZSadn2pwYMHS61atUz9jxozZowpqNZuM80QrVixQnbv3i2xsbFmv1aj6/7x48eb+Yw04Nm6dassXbpU5s6daxtCqfunTZtm5l3SEXDvv/++HD58WD766CPxVNHlwiUiJEjSs3PkzKV0W5cbAADwsQBJh+PHx8fL1KlTTaG1BitaNG0txNYuL/tskI4607mPJk+ebLrSdKJInRDSOgeS0qBJ64UGDRokiYmJJkiaOXOmw0SRY8eOlYyMDHn22WdNGw2UNBPVsGFD8VSBgQEmKPrvj8lmyRECJAAASo5b50HyZqU9D5IauXyv/OvAjzK5b1P57S8blMprAgDgSzx+HiTcwqK1CalcPgAAShABkhdhLiQAAEoHAZIXYS4kAABKBwGSF2kQdW25kbjkDEnNvOru0wEAwGcRIHmRCpEhUqVMqLl/gjokAABKDAGSl6GbDQCAkkeA5GUIkAAAKHkESF7GuuQIXWwAAJQcAiQvw1xIAACUPAIkL9Og6rWRbCfiU4RJ0AEAKBkESF6mbuVICQgQSc64KhdTs9x9OgAA+CQCJC8THhIktSpGmPvUIQEAUDIIkLwQS44AAFCyCJC8EIXaAACULAIkr54LKcXdpwIAgE8iQPLmkWwsNwIAQIkgQPLiDNLJi2mSk2tx9+kAAOBzCJC8UM2KERIaHChZV3Pl3OV0d58OAAA+hwDJCwUFBkhMlUhz/zjdbAAAFDsCJK8f6k+hNgAAxY0AyUvVj6JQGwCAkkKA5KUaVL2WQaKLDQCA4keA5O2TRcanuvtUAADwOQRIXl6DdC4pXTKyc9x9OgAA+BQCJC9VuUyolA8PFotF5IeLae4+HQAAfAoBkpcKCAiQ+rYZtRnJBgBAcSJA8mIsWgsAQMkgQPJiFGoDAFAyCJC8WP3rQ/1ZtBYAgOJFgOQLs2mz3AgAAMWKAMmLxVS5FiAlpmbJ5bQsd58OAAA+gwDJi5UJC5bq5cPNfbJIAAAUHwIkL0c3GwAAxY8AyVfWZGPJEQAAig0BkpcjgwQAQPEjQPKVDBIj2QAAKDYESF6uftS15UZOJqRKbq7F3acDAIBPIEDycrUrRUhwYICkZ+fI+SsZ7j4dAAB8gkcESIsWLZKYmBgJDw+Xjh07yq5du/Jtv2rVKmnSpIlp36JFC1m/fr3D/pSUFBk1apTUrl1bIiIipFmzZrJ48WKHNnfeeadZ8NX+NmLECPE2IUGBUrdKpLl/gkJtAAB8I0BauXKljBs3TqZNmyZ79+6VVq1aSa9eveTChQsu22/fvl0GDhwow4YNk3379km/fv3M7eDBg7Y2erwNGzbIsmXL5NChQzJ27FgTMK1du9bhWE899ZT8+OOPtttrr70m3rwm2/fUIQEA4BsB0ty5c02gMnToUFumJzIyUt59912X7V9//XXp3bu3jB8/Xpo2bSrTp0+XNm3ayMKFCx2CqCFDhpgskWamhg8fbgIv58yUvk716tVtt/Lly4tXj2QjgwQAgPcHSFlZWbJnzx7p0aPHTycUGGge79ixw+VzdLt9e6UZJ/v2Xbp0Mdmis2fPisVikS1btsjRo0elZ8+eDs/74IMPJCoqSpo3by4TJ06UtLS0PM81MzNTkpOTHW6eVqh9IiHF3acCAIBPCHbniyckJEhOTo5ER0c7bNfHhw8fdvmcuLg4l+11u9WCBQtM1khrkIKDg03Q9fbbb0vXrl1tbR577DGpV6+e1KxZUw4cOCB//OMf5ciRI/Lxxx+7fN1Zs2bJiy++KJ6IuZAAAPChAKmkaIC0c+dOk0XSIGjbtm0ycuRIEwxZs08aQFlpoXeNGjWke/fu8v3330vDhg1vOKZmmLS2yUozSHXq1BFPmgvp9KV0ybqaK6HBbu85BQDAq7k1QNLuraCgIDl//rzDdn2sNUGu6Pb82qenp8ukSZNk9erV0rdvX7OtZcuWsn//fpk9e/YN3XNWOnpOHTt2zGWAFBYWZm6eqFq5MCkTGiSpWTly+lKaNKx6rcsNAAAUjVtTDaGhodK2bVvZvHmzbVtubq553LlzZ5fP0e327dXGjRtt7bOzs81Nu9XsaSCmx86LBlBKM0neRqcoqM+abAAA+E4Xm3Zb6Yizdu3aSYcOHWT+/PmSmppqRrWpwYMHS61atUwNkBozZox069ZN5syZYzJEK1askN27d0tsbKzZryPRdL+OctM5kLSLbevWrbJ06VIzYk5pN9ry5cvlnnvukSpVqpgapGeffdbUKGm2yRtpofbBs8nXC7Uda7QAAICXBUgDBgyQ+Ph4mTp1qim0bt26tZnDyFqIferUKYdskI5Q0+Bm8uTJpiutcePGsmbNGjMSzUqDJq0ZGjRokCQmJpogaebMmbaJIDVztWnTJlswprVE/fv3N8f0VhRqAwBQfAIsOg4ehaZF2hUqVJCkpCSPmD9pzb6zMnblfulYv7Ks/J3r7kkAAPxdcgG/vxnu5CPIIAEAUHwIkHyEtUj7wpVMScm86u7TAQDAqxEg+Yjy4SESVfbaNAQsOQIAwK0hQPIh1kVrj7PkCAAAt4QAyYdQhwQAQPEgQPLBOqQTCanuPhUAALwaAZIPIYMEAEDxIEDyIQ3tlhtheisAAIqOAMmH1KkcKYEBYob5x6dkuvt0AADwWgRIPiQsOEhqV4o09xnqDwBA0REg+RjqkAAAuHUESD6GAAkAgFtHgORjGlgLtRnqDwBAkREg+ZgGUWXNz+PxKe4+FQAAvBYBko9OFnkqMU2u5uS6+3QAAPBKBEg+pkb5cAkLDpTsHIucvZzu7tMBAMArESD5mMDAAFuhNnVIAAAUDQGSL49ki2dNNgAAioIAyQcx1B8AgFtDgOSDGlS9PpItgZFsAAAUBQGSD6KLDQCAW0OA5IMaXK9BOpeUIelZOe4+HQAAvA4Bkg+qVCZUKkaGmPsnL1KoDQBAYREg+SgKtQEAKDoCJB9fcuQEa7IBAFBoBEg+vmjt96zJBgBAoREg+Si62AAAKDoCJB9FgAQAQNERIPmomCrXutgup2XLpdQsd58OAABehQDJR0WEBknNCuHmPovWAgBQOARIfrDkCCPZAAAoHAIkP6hDOs5INgAACoUAyYdRqA0AQNEQIPmw+tfnQqKLDQCAwiFA8oNFazVAys21uPt0AADwGgRIPqxWxQgJCQqQzKu58mNyhrtPBwAAr0GA5MOCgwKl3vX5kE7Ep7r7dAAA8BoESD7ONpItIcXdpwIAgNfwiABp0aJFEhMTI+Hh4dKxY0fZtWtXvu1XrVolTZo0Me1btGgh69evd9ifkpIio0aNktq1a0tERIQ0a9ZMFi9e7PJYFotF+vTpIwEBAbJmzRrx1Tqk42SQAADwngBp5cqVMm7cOJk2bZrs3btXWrVqJb169ZILFy64bL99+3YZOHCgDBs2TPbt2yf9+vUzt4MHD9ra6PE2bNggy5Ytk0OHDsnYsWNNwLR27dobjjd//nwTHPkqhvoDAOCFAdLcuXPlqaeekqFDh9oyPZGRkfLuu++6bP/6669L7969Zfz48dK0aVOZPn26tGnTRhYuXOgQRA0ZMkTuvPNOk5kaPny4CbycM1P79++XOXPm5PlavoAACQAALwuQsrKyZM+ePdKjR4+fTigw0DzesWOHy+fodvv2SjNO9u27dOliskVnz541XWhbtmyRo0ePSs+ePW1t0tLS5LHHHjPde9WrVxdfnwvpzKU0ybya4+7TAQDAKwS788UTEhIkJydHoqOjHbbr48OHD7t8TlxcnMv2ut1qwYIFJmukNUjBwcEm6Hr77bela9eutjbPPvusCaQeeOCBAp1rZmamuVklJyeLN6haNkzKhQXLlcyrcupimjSOLufuUwIAwOO5NUAqKRog7dy502SR6tWrJ9u2bZORI0dKzZo1TfZJt3/22WemhqmgZs2aJS+++KJ4G62v0izSgTNJcjwhlQAJAABP72KLioqSoKAgOX/+vMN2fZxXt5duz699enq6TJo0ydQ23XfffdKyZUtToD1gwACZPXu2aaPB0ffffy8VK1Y0GSa9qf79+5u6JVcmTpwoSUlJttvp06fFW1CHBACAFwVIoaGh0rZtW9m8ebNtW25urnncuXNnl8/R7fbt1caNG23ts7OzzU271expIKbHVhMmTJADBw6YIm3rTc2bN0+WLFni8nXDwsKkfPnyDjevC5AY6g8AgHd0semQfB1x1q5dO+nQoYMZdp+ammpGtanBgwdLrVq1TBeXGjNmjHTr1s2MPuvbt6+sWLFCdu/eLbGxsWa/Bi66X0e56RxI2sW2detWWbp0qckqKc02ucpQ1a1bV+rXry++hgwSAABeFiBp11d8fLxMnTrVFFq3bt3azGFkLcQ+deqUQzZIC6uXL18ukydPNl1pjRs3NhM8Nm/e3NZGgybtEhs0aJAkJiaaIGnmzJkyYsQI8UcNosqan1qDBAAAbi7AouPgUWg6iq1ChQqmHsnTu9tSMq9K82mfmvsHXugp5cND3H1KAAB49Pe32yeKRMkrGxYs1cqFmfvUIQEAcHMESH6COiQAAAqOAMlPNLg+ozZ1SAAA3BwBkp8ggwQAQMERIPnZSLYTCSnuPhUAADweAZKfsC5aq0XaDFwEACB/BEh+ok6lSAkKDJDUrBy5cOWnRXcBAMCNCJD8RGhwoNSpFGHuH2fJEQAA8kWA5Eco1AYAoGAIkPxIfQq1AQAoEAIkP5wL6QRrsgEAUPwB0unTp+XMmTO2x7t27ZKxY8dKbGxsUQ6HUtIg6vpkkdQgAQBQ/AHSY489Jlu2bDH34+Li5O677zZB0vPPPy8vvfRSUQ6JUhzqfyoxTbJzcrnmAAAUZ4B08OBB6dChg7n/4YcfSvPmzWX79u3ywQcfyHvvvVeUQ6IURJcLl4iQILmaa5Ezl9K55gAAFGeAlJ2dLWFh11aH37Rpk9x///3mfpMmTeTHH38syiFRCgIDAyTmejcbM2oDAFDMAdLPf/5zWbx4sXz++eeyceNG6d27t9l+7tw5qVKlSlEOiVJCHRIAACUUIL366qvy5z//We68804ZOHCgtGrVymxfu3atresNnomRbAAA3FywFIEGRgkJCZKcnCyVKlWybR8+fLhERkYW5ZAo5ckiGckGAEAxZ5DS09MlMzPTFhz98MMPMn/+fDly5IhUq1atKIdEKWE2bQAASihAeuCBB2Tp0qXm/uXLl6Vjx44yZ84c6devn7z11ltFOSRKOUCKS86Q1MyrXHcAAIorQNq7d6/88pe/NPc/+ugjiY6ONlkkDZreeOONohwSpaRiZKhULhNq7p+8mMp1BwCguAKktLQ0KVeunLn/73//W379619LYGCgdOrUyQRK8Gx0swEAUAIBUqNGjWTNmjVmyZFPP/1UevbsabZfuHBBypcvX5RDwg1D/U+w5AgAAMUXIE2dOlWee+45iYmJMcP6O3fubMsm3X777UU5JNyw5MhxFq0FAKD4hvk/9NBD8otf/MLMmm2dA0l1795dHnzwwaIcEu6YLJIACQCA4guQVPXq1c3tzJkz5nHt2rWZJNJL1I8qa36eiE8Ri8UiAQEB7j4lAAC8v4stNzdXXnrpJalQoYLUq1fP3CpWrCjTp083++DZ6lWJFI2JkjOuSmJqlrtPBwAA38ggPf/88/LOO+/IK6+8InfccYfZ9sUXX8gLL7wgGRkZMnPmzOI+TxSj8JAgqVkhQs5eTpcTCalSpey1hYcBAMAtBEjvv/++/OUvf5H777/ftq1ly5ZSq1YtefrppwmQvGRNNg2QdMmRdjGV3X06AAB4fxdbYmKiNGnS5Ibtuk33wfNRqA0AQDEHSDpybeHChTds122aSYI3TRaZ4u5TAQDAN7rYXnvtNenbt69s2rTJNgfSjh07zMSR69evL+5zRAmoX/X6SDaG+gMAUDwZpG7dusnRo0fNnEe6WK3edLmR7777Tv76178W5ZBwUxfbyYtpkpNr4foDAGAnwKIT4RSTb775Rtq0aSM5OTni65KTk800B0lJSV65vIoGRU2nbpCsq7ny+f/dJXUqR7r7lAAA8Jjv7yJlkOD9ggIDJKbKtaCIGbUBAHBEgOTHbIXa8RRqAwBgjwDJj9mWHKFQGwCAoo9i00Ls/GixNrwHcyEBAFAMAZIWNd1s/+DBgwtzSLhR/arWuZBSeR8AAChqgLRkyRIpCYsWLZI//elPEhcXZyahXLBggXTo0CHP9qtWrZIpU6bIyZMnpXHjxvLqq6/KPffcY9ufkpIiEyZMkDVr1sjFixelfv368swzz8iIESNsbX73u9+ZeZzOnTsnZcuWlS5dupjjuJoh3NczSLrkSEZ2jlmjDQAAeEAN0sqVK2XcuHEybdo02bt3rwmQevXqJRcuXHDZfvv27TJw4EAZNmyY7Nu3T/r162duBw8etLXR423YsEGWLVsmhw4dkrFjx8qoUaNk7dq1tjZt27Y1AZ/u//TTT0VnO+jZs6dfTFFgVblMqJQPDxad6OGHi2nuPh0AAHxzHqSi6Nixo7Rv3962dElubq7UqVNHRo8ebbJAzgYMGCCpqamybt0627ZOnTpJ69atZfHixeZx8+bNTTvNMtkHRH369JEZM2a4PI8DBw6Y4OzYsWPSsGFDn58HyeqBRV/KN6cvy+LH20jv5jXcfToAAJQor5gHKSsrS/bs2SM9evT46YQCA81jXbrEFd1u315pxsm+vXaXabbo7NmzJjO0ZcsWM/O3Zohc0YBLs0naFafBmSuZmZnmotrffAGF2gAAeFiAlJCQYLq0oqOjHbbrY61HckW336y91jA1a9ZMateuLaGhodK7d29T59S1a1eH57355pum/khvn3zyiWzcuNG0d2XWrFkm4rTe8gqkvHcuJAq1AQDwmBqkkqAB0s6dO00WSTNUc+bMkZEjR5qibHuDBg0ydUxbt26Vn/3sZ/LII49IRkaGy2NOnDjRpOOsN12Y16cCJEayAQBQtFFsxS0qKkqCgoLk/PnzDtv1cfXq1V0+R7fn1z49PV0mTZokq1evlr59+5ptLVu2lP3798vs2bMduues2SAdCad1TJUqVTLP0yJwZ2FhYebmaxow1B8AAM/KIGl3lhZPb9682bZNi7T1cefOnV0+R7fbt1faNWZtn52dbW5ay2RPAzE9dl60VklvWmvkT2KqXMsgXUzNkqS0bHefDgAAHsGtGSTrkPwhQ4ZIu3btzNxH8+fPN0XTQ4cONft14slatWqZGiA1ZswY6datm+k20wzRihUrZPfu3RIbG2v2a0W67h8/frxERERIvXr1TBfa0qVLZe7cuabN8ePHzfQCWrRdtWpVOXPmjLzyyiumvf18Sv6gTFiwVC8fLnHJGXI8IUVur1vJ3acEAIDbuT1A0uH48fHxMnXqVFNorcP1dQ4jayH2qVOnHLJBOkJt+fLlMnnyZNOVpt1jOiGkDu230qBJa4a0xigxMdEESTNnzrRNFBkeHi6ff/65CcYuXbpkXksLuHWOpWrVqom/0TokDZC0DokACQAAD5gHyVv5yjxIatLqb2X5V6dk9K8ayR963ubu0wEAwL/nQYJnYC4kAAAcESDhp5FszIUEAIBBgASpH1XWXAWtQcrNpccVAAACJEjtShESHBgg6dk5cv6K64kyAQDwJwRIkJCgQKlbOdJcCbrZAAAgQILTkiPHWXIEAAAySLiGNdkAAPgJXWwwGlT9qVAbAAB/R4AExy62+BSuCADA7xEgwWEupNOX0iXrat6L+gIA4A8IkGBUKxcmkaFBkpNrkdOX0rgqAAC/RoAEIyAg4KdCbWbUBgD4OQIk2DCSDQCAawiQcMNItuMJFGoDAPwbARJsGthGsjHUHwDg3wiQYEMXGwAA1xAgwSbmegbpwpVMScm8ypUBAPgtAiTYVIgIkaiyoeb+SWbUBgD4MQIkOGgQZS3Upg4JAOC/CJDggCVHAAAgQIKT+teXHGHRWgCAPyODBAeMZAMAgAAJecyFpMuNWCwWrg8AwC+RQYKDulUiJTBA5ErmVUlIyeLqAAD8EgESHIQFB0ntSpHmPnVIAAB/RYCEGzCSDQDg7wiQcAMKtQEA/o4ACTdocH2oP5NFAgD8FQESbkAGCQDg7wiQkGeA9MPFVMnJZag/AMD/ECDhBjUrREhYcKBk51jk7KV0rhAAwO8QIOHGD0VggC2L9H1CClcIAOB3CJCQfx1SfCpXCADgdwiQ4BKF2gAAf0aABJcIkAAA/owACfnOhcRyIwAAf0SABJcaRJU1P89eTpeM7ByuEgDArxAgwaVKZUKlYmSIuU8WCQDgbzwiQFq0aJHExMRIeHi4dOzYUXbt2pVv+1WrVkmTJk1M+xYtWsj69esd9qekpMioUaOkdu3aEhERIc2aNZPFixfb9icmJsro0aPltttuM/vr1q0rzzzzjCQlJZXY7+iNqEMCAPgrtwdIK1eulHHjxsm0adNk79690qpVK+nVq5dcuHDBZfvt27fLwIEDZdiwYbJv3z7p16+fuR08eNDWRo+3YcMGWbZsmRw6dEjGjh1rAqa1a9ea/efOnTO32bNnm+e99957pr0eEz8hQAIA+KsAi8Xi1rUkNGPUvn17WbhwoXmcm5srderUMRmeCRMm3NB+wIABkpqaKuvWrbNt69Spk7Ru3dqWJWrevLlpN2XKFFubtm3bSp8+fWTGjBl5ZqUef/xxc+zg4OCbnndycrJUqFDBZJ3Kly8vvmjhZ/+T2f8+Kv3b1JY5j7Ry9+kAAHDLCvr97dYMUlZWluzZs0d69Ojx0wkFBprHO3bscPkc3W7fXmnGyb59ly5dTLbo7NmzovHfli1b5OjRo9KzZ888z8V6ofIKjjIzM81Ftb/5uvrXC7VPMJs2AMDPuDVASkhIkJycHImOjnbYro/j4uJcPke336z9ggULTN2R1iCFhoZK7969TZ1T165d8zyP6dOny/Dhw/M811mzZpmI03rTLJevY6g/AMBfub0GqSRogLRz506TRdIM1Zw5c2TkyJGyadOmG9pqJqhv374moHrhhRfyPObEiRNNlsl6O336tPi6mCrX5kK6lJYtl1Kz3H06AACUmpsX25SgqKgoCQoKkvPnzzts18fVq1d3+Rzdnl/79PR0mTRpkqxevdoEPqply5ayf/9+U5Rt3z135coVk10qV66caR8Scm1YuythYWHm5k8iQoOkZoVwOZeUIccTUqVtmVB3nxIAAL6fQdLuLy2e3rx5s22bFmnr486dO7t8jm63b682btxoa5+dnW1uWstkTwMxPbZ95khrkvQcNNOkUwbgRvWZURsA4IfcmkGyDskfMmSItGvXTjp06CDz5883I8mGDh1q9g8ePFhq1aplaoDUmDFjpFu3bqbbTDNEK1askN27d0tsbKzZr4XWun/8+PFmjqN69erJ1q1bZenSpTJ37lyH4CgtLc1MBWBfdF21alUTTOGnof5fHrtIoTYAwK+4PUDS4fjx8fEydepUU2itw/V1TiJrIfapU6ccskE6Qm358uUyefJk05XWuHFjWbNmjRnab6VBk9YMDRo0yEwKqUHSzJkzZcSIEWa/zrf01VdfmfuNGjVyOJ8TJ06YSSvhuOQIs2kDAPyJ2+dB8lb+MA+S2nLkggxd8rU0qV5ONox1PQoQAABv4RXzIMHzNYgqY8sg5eYSSwMA/AMBEvJVq2KEhAQFSObVXPkxOYOrBQDwCwRIyFdwUKDUrRxp7p+IT+VqAQD8AgESboolRwAA/oYACTfV8PpcSDpZJAAA/oAACQWaC0kdp4sNAOAnCJBQ4ACJuZAAAP6CAAkFXm7kzKU0ybyawxUDAPg8AiTcVNWyYVI2LFh0GqTTiWlcMQCAzyNAwk0FBARQhwQA8CsESCiQBte72ahDAgD4AwIkFAgj2QAA/oQACQXCSDYAgD8hQEKBNIgqa34yWSQAwB8QIKFAYqKurceWkJIpyRnZXDUAgE8jQEKBlAsPkarlwsz9kyw5AgDwcQRIKLAGzKgNAPATBEgo9FD/71mTDQDg4wiQUGCMZAMA+AsCJBRY/esj2U4kpHDVAAA+jQAJhc8gxaeKxWLhygEAfBYBEgqsbuVICQoMkNSsHIm/ksmVAwD4LAIkFFhocKDUqRRh7jNhJADAlxEgoVBYkw0A4A8IkFAoFGoDAPwBARIKpf71uZBOMJs2AMCHESChSLNpU4MEAPBlBEgoUg3SqYtpcjUnl6sHAPBJBEgolOrlwyUiJEiu5lrkzKV0rh4AwCcRIKFwH5jAAImxdbMxozYAwDcRIKHodUgsWgsA8FEESCg0Fq0FAPg6AiQUGgESAMDXESCh0BowFxIAwMcRIKHIGaQfkzIkLesqVxAA4HMIkFBoFSNDpXKZUHOfGbUBAL6IAAlFQh0SAMCXESDh1gIkhvoDAHyQ2wOkRYsWSUxMjISHh0vHjh1l165d+bZftWqVNGnSxLRv0aKFrF+/3mF/SkqKjBo1SmrXri0RERHSrFkzWbx4sUOb2NhYufPOO6V8+fISEBAgly9fLpHfzZeRQQIA+DK3BkgrV66UcePGybRp02Tv3r3SqlUr6dWrl1y4cMFl++3bt8vAgQNl2LBhsm/fPunXr5+5HTx40NZGj7dhwwZZtmyZHDp0SMaOHWsCprVr19rapKWlSe/evWXSpEml8nv6oobXR7KxaC0AwBcFWCwWi7teXDNG7du3l4ULF5rHubm5UqdOHRk9erRMmDDhhvYDBgyQ1NRUWbdunW1bp06dpHXr1rYsUfPmzU27KVOm2Nq0bdtW+vTpIzNmzHA43n/+8x+566675NKlS1KxYsVCnXtycrJUqFBBkpKSTCbK3xyJuyK95m+T8uHB8s20niYTBwCApyvo97fbMkhZWVmyZ88e6dGjx08nExhoHu/YscPlc3S7fXulGSf79l26dDHZorNnz4rGflu2bJGjR49Kz549S/C38T/1qkSKxkTJGVclMTXL3acDAECxChY3SUhIkJycHImOjnbYro8PHz7s8jlxcXEu2+t2qwULFsjw4cNNDVJwcLAJut5++23p2rXrLZ1vZmamudlHoP4sPCRIalaIkLOX081Q/yplw9x9SgAA+E6RdnHTAGnnzp0mi6QZqjlz5sjIkSNl06ZNt3TcWbNmmZSc9aZdgf7OOqM2dUgAAF/jtgApKipKgoKC5Pz58w7b9XH16tVdPke359c+PT3dFF7PnTtX7rvvPmnZsqUp0NaapNmzZ9/S+U6cONH0V1pvp0+fFn/HSDYAgK9yW4AUGhpqiqc3b95s26ZF2vq4c+fOLp+j2+3bq40bN9raZ2dnm5t2q9nTQEyPfSvCwsJMMZf9zd81YC4kAICPclsNknVI/pAhQ6Rdu3bSoUMHmT9/vhmlNnToULN/8ODBUqtWLdO9pcaMGSPdunUz3WZ9+/aVFStWyO7du828RkqDFt0/fvx4MwdSvXr1ZOvWrbJ06VKTVbLSmiW9HTt2zDz+9ttvpVy5clK3bl2pXLmyW66FN6pftaz5eTwhxd2nAgCA7wRI2vUVHx8vU6dONQGLDtfXOYyshdinTp1yyAbpCLXly5fL5MmTTVda48aNZc2aNWZov5UGTdodNmjQIElMTDRB0syZM2XEiBG2NjolwIsvvmh7bC3gXrJkiTzxxBOl9Nv7Tgbp5MU0ycm1SFAgQ/0BAL7BrfMgeTN/nwdJaVDUdMoGycrJlc//7y6pUznS3acEAIB3z4ME76cZI50PSelQfwAAfAUBEm4JI9kAAL6IAAm3pMH1Qm0ySAAAX0KAhGIp1P4+npFsAADfQYCEW1L/+mzaZJAAAL6EAAnFUoOka7JlZOdwNQEAPoEACbekSplQKRceLDpZxKnENK4mAMAnECDhlgQEBNjqkI7HM9QfAOAbCJBwyxjJBgDwNQRIKLY6pOOMZAMA+AgCJNwyJosEAPgaAiTcMgIkAICvIUBCsQVIF1OzJCktmysKAPB6BEi4ZWXCgqV6+XBz/8RFRrIBALwfARKKuZuNJUcAAN6PAAnFuuQIcyEBAHwBARKKhW2yyAS62AAA3o8ACcXbxcZs2gAAH0CAhGIf6m/RhdkAAPBiBEgoFnUqR0pwYICkZ+fI+eRMrioAwKsRIKFYhAQFSt3KkeY+S44AALwdARKKf002CrUBAF6OAAnFhiVHAAC+ggAJxT4XkhZqAwDgzQiQUGzIIAEAfAUBEopNw6plzc9TiWmSnZPLlQUAeC0CJBSbauXCJDI0SHJyLSZIAgDAWxEgodgEBAQwozYAwCcQIKFYUYcEAPAFBEgoVixaCwDwBQRIKKGh/ilcWQCA1yJAQrFqEHVtJBtzIQEAvBkBEopVzPXlRnTB2pTMq1xdAIBXIkBCsaoQESJRZUPN/ZPMqA0A8FIESCh2LFoLAPB2BEgouaH+8azJBgDwTgRIKHb1bYXajGQDAHgnAiQUuwa2of5kkAAA3okACSU3WWR8qlgsFq4wAMDreESAtGjRIomJiZHw8HDp2LGj7Nq1K9/2q1atkiZNmpj2LVq0kPXr1zvsT0lJkVGjRknt2rUlIiJCmjVrJosXL3Zok5GRISNHjpQqVapI2bJlpX///nL+/PkS+f38Td0qkRIQIHIl86okpGS5+3QAAPC+AGnlypUybtw4mTZtmuzdu1datWolvXr1kgsXLrhsv337dhk4cKAMGzZM9u3bJ/369TO3gwcP2tro8TZs2CDLli2TQ4cOydixY03AtHbtWlubZ599Vv75z3+aYGvr1q1y7tw5+fWvf10qv7OvCwsOktqVIsx9utkAAN4owOLmPhDNGLVv314WLlxoHufm5kqdOnVk9OjRMmHChBvaDxgwQFJTU2XdunW2bZ06dZLWrVvbskTNmzc37aZMmWJr07ZtW+nTp4/MmDFDkpKSpGrVqrJ8+XJ56KGHzP7Dhw9L06ZNZceOHeZ4N5OcnCwVKlQwxypfvnyxXAvRtyI7TXzBb5fuli+PJchzPW+T3s2ru/t0AABeqEL5ClI2PKRYj1nQ7+9gcaOsrCzZs2ePTJw40bYtMDBQevToYQIVV3S7ZojsacZpzZo1tsddunQx2aInn3xSatasKf/5z3/k6NGjMm/ePLNfXzM7O9u8jpV22dWtWzfPACkzM9Pc7C9wsdPg6OWa4gv+ov8JF5Ft128AABTSyru/kgF3NBG/62JLSEiQnJwciY6Odtiuj+Pi4lw+R7ffrP2CBQtM3ZHWIIWGhkrv3r1NnVPXrl1tx9DtFStWLPDrzpo1y0Sc1ptmuQAAQMkJcmOU4tYMUknRAGnnzp0mi1SvXj3Ztm2bKcjWbJJ91qgwNMtln7nSDFKxB0khkSKTzhXvMQEA8FIP6feiPwZIUVFREhQUdMPoMX1cvbrruhXdnl/79PR0mTRpkqxevVr69u1rtrVs2VL2798vs2fPNgGSttXuvcuXLztkkfJ73bCwMHMrUTr0K/TaEHkAAOA+bu1i024uLZ7evHmzbZsWaevjzp07u3yObrdvrzZu3Ghrr7VFetNaJnsaiOmxlb5mSEiIw3GOHDkip06dyvN1AQCA/3B7F5t2Ww0ZMkTatWsnHTp0kPnz55tRakOHDjX7Bw8eLLVq1TI1QGrMmDHSrVs3mTNnjskQrVixQnbv3i2xsbFmv1ak6/7x48ebOZC0i02H8S9dulTmzp1r2mgNkU4ToK9duXJl8xwdNafBUUFGsAEAAN/m9gBJh+PHx8fL1KlTTYG0DtfXOYyshdia1bHPBukINR2eP3nyZNOV1rhxYzOCTYf2W2nQpDVDgwYNksTERBMkzZw5U0aMGGFroyPa9Lg6QaSOTtORcG+++WYp//YAAMATuX0eJG9VIvMgAQAAj/j+dvtM2gAAAJ6GAAkAAMAJARIAAIATAiQAAAAnBEgAAABOCJAAAACcECABAAA4IUACAABwQoAEAADgaUuNeCvrBOQ6IycAAPAO1u/tmy0kQoBURFeuXDE/69SpU9RDAAAAN36P65IjeWEttiLKzc2Vc+fOSbly5SQgIKCoh/H5KF0DyNOnT7NenQfg/fAsvB+ehffDf94Pi8VigqOaNWuaRevzQgapiPSi1q5du6hP9yv64WZBX8/B++FZeD88C++Hf7wfFfLJHFlRpA0AAOCEAAkAAMAJARJKTFhYmEybNs38hPvxfngW3g/PwvvhWcI84PuDIm0AAAAnZJAAAACcECABAAA4IUACAABwQoAEAADghAAJxWrWrFnSvn17M8N4tWrVpF+/fnLkyBGusod45ZVXzMzvY8eOdfep+LWzZ8/K448/LlWqVJGIiAhp0aKF7N69292n5ZdycnJkypQpUr9+ffNeNGzYUKZPn37TdbpQPLZt2yb33XefmdVa/9+0Zs0ah/36PkydOlVq1Khh3p8ePXrI//73PykNBEgoVlu3bpWRI0fKzp07ZePGjZKdnS09e/aU1NRUrrSbff311/LnP/9ZWrZs6e5T8WuXLl2SO+64Q0JCQuSTTz6R//73vzJnzhypVKmSu0/NL7366qvy1ltvycKFC+XQoUPm8WuvvSYLFixw96n5hdTUVGnVqpUsWrTI5X59L9544w1ZvHixfPXVV1KmTBnp1auXZGRklPi5McwfJSo+Pt5kkjRw6tq1K1fbTVJSUqRNmzby5ptvyowZM6R169Yyf/583g83mDBhgnz55Zfy+eefc/09wL333ivR0dHyzjvv2Lb179/fZCuWLVvm1nPzNwEBAbJ69WrT82DNHmlm6Q9/+IM899xzZltSUpJ5v9577z159NFHS/R8yCChROmHWVWuXJkr7Uaa1evbt69JT8O91q5dK+3atZOHH37Y/PFw++23y9tvv83b4iZdunSRzZs3y9GjR83jb775Rr744gvp06cP74mbnThxQuLi4hz+v6VrqHXs2FF27NhR4q/PYrUoMbm5uabWRbsTmjdvzpV2kxUrVsjevXtNFxvc7/jx46ZLZ9y4cTJp0iTzvjzzzDMSGhoqQ4YMcffp+WVGT1eOb9KkiQQFBZmapJkzZ8qgQYPcfWp+Ly4uzlwDzRjZ08fWfSWJAAklmrU4ePCg+WsM7nH69GkZM2aMqQcLDw/nbfCQPxw0g/Tyyy+bx5pB0n8nWmNBgFT6PvzwQ/nggw9k+fLl8vOf/1z2799v/rDTrh3eD/9GFxtKxKhRo2TdunWyZcsWqV27NlfZTfbs2SMXLlww9UfBwcHmpvVgWvSo9/WvZZQuHY3TrFkzh21NmzaVU6dO8Va4wfjx400WSetZdDThb37zG3n22WfNiFy4V/Xq1c3P8+fPO2zXx9Z9JYkACcVKi+o0ONJCu88++8wMnYX7dO/eXb799lvzV7H1ptkL7T7Q+9qlgNKlXc7OU19o/Uu9evV4K9wgLS1NAgMdvwr134Vm+uBe+v2hgZDWiFlpd6iOZuvcuXOJvz5dbCj2bjVNVf/jH/8wcyFZ+4m1sE5HhaB06XvgXP+lw2R1/h3qwtxDsxNaGKxdbI888ojs2rVLYmNjzQ2lT+fg0ZqjunXrmi62ffv2ydy5c+XJJ5/k7SilEbbHjh1zKMzWP950YI++J9rdqSNvGzdubAImnbNKuz+tI91KlAUoRvqRcnVbsmQJ19lDdOvWzTJmzBh3n4Zf++c//2lp3ry5JSwszNKkSRNLbGysu0/JbyUnJ5t/D3Xr1rWEh4dbGjRoYHn++ectmZmZ7j41v7BlyxaX3xlDhgwx+3Nzcy1TpkyxREdHm38v3bt3txw5cqRUzo15kAAAAJxQgwQAAOCEAAkAAMAJARIAAIATAiQAAAAnBEgAAABOCJAAAACcECABAAA4IUACgGISEBAga9as4XoCPoAACYBPeOKJJ0yA4nzr3bu3u08NgBdiLTYAPkODoSVLljhsCwsLc9v5APBeZJAA+AwNhnT1b/tbpUqVzD7NJr311lvSp08fs3BygwYN5KOPPnJ4/rfffiu/+tWvzH5d0Hf48OFmMU177777rlnUVF+rRo0aMmrUKIf9CQkJ8uCDD0pkZKRZYHPt2rWl8JsDKG4ESAD8hq4E3r9/f/nmm29k0KBB8uijj8qhQ4fMvtTUVOnVq5cJqL7++mtZtWqVbNq0ySEA0gBr5MiRJnDSYEqDn0aNGjm8xosvviiPPPKIHDhwQO655x7zOomJiaX+uwK4RaWyJC4AlDBd/TsoKMhSpkwZh9vMmTPNfv3f3YgRIxye07FjR8vvf/97cz82NtZSqVIlS0pKim3/v/71L0tgYKAlLi7OPK5Zs6ZZ6T0v+hqTJ0+2PdZj6bZPPvmk2H9fACWLGiQAPuOuu+4yWR57lStXtt3v3Lmzwz59vH//fnNfM0mtWrWSMmXK2PbfcccdkpubK0eOHDFddOfOnZPu3bvnew4tW7a03ddjlS9fXi5cuHDLvxuA0kWABMBnaEDi3OVVXLQuqSBCQkIcHmtgpUEWAO9CDRIAv7Fz584bHjdt2tTc159am6S1SFZffvmlBAYGym233SblypWTmJgY2bx5c6mfN4DSRwYJgM/IzMyUuLg4h23BwcESFRVl7mvhdbt27eQXv/iFfPDBB7Jr1y555513zD4tpp42bZoMGTJEXnjhBYmPj5fRo0fLb37zG4mOjjZtdPuIESOkWrVqZjTclStXTBCl7QD4FgIkAD5jw4YNZui9Pc3+HD582DbCbMWKFfL000+bdn/729+kWbNmZp8Oy//0009lzJgx0r59e/NYR7zNnTvXdiwNnjIyMmTevHny3HPPmcDroYceKuXfEkBpCNBK7VJ5JQBwI60FWr16tfTr14/3AcBNUYMEAADghAAJAADACTVIAPwC1QQACoMMEgAAgBMCJAAAACcESAAAAE4IkAAAAJwQIAEAADghQAIAAHBCgAQAAOCEAAkAAMAJARIAAIA4+n+I9MiC1hCryQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ckpt_path = \"results/checkpoints/gnn_rw_k1_keep0.8_num_steps_1.pt\"\n",
    "model, history = train_gnn_sparsifier_on_dataset(train_dir=\"../data/synthetic_graphs/ba/train\", \n",
    "                                                 val_dir=\"../data/synthetic_graphs/ba/val\",\n",
    "                                                 keep_ratio=0.8, \n",
    "                                                 num_steps=1, \n",
    "                                                 num_epochs=10, \n",
    "                                                 learning_rate=1e-3, \n",
    "                                                 lambda_sparsity=2.0,\n",
    "                                                 device=\"cpu\", \n",
    "                                                 print_every=1, \n",
    "                                                 checkpoint_path=ckpt_path, \n",
    "                                                 )\n",
    "epochs = history[\"epoch\"] \n",
    "plt.figure()\n",
    "plt.plot(epochs, history[\"train_loss\"], label=\"train\") \n",
    "plt.plot(epochs, history[\"val_loss\"], label=\"val\") \n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"RW + sparsity loss over epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6fef85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Using device: cpu\n",
      "[train] Loaded 120 train graphs and 40 val graphs\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 2...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m ckpt_path = \u001b[33m\"\u001b[39m\u001b[33mresults/checkpoints/gnn_rw_k1_keep0.8_num_steps_2.pt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model, history = \u001b[43mtrain_gnn_sparsifier_on_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/synthetic_graphs/ba/train\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mval_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/synthetic_graphs/ba/val\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mkeep_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mlambda_sparsity\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m epochs = history[\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m] \n\u001b[32m     14\u001b[39m plt.figure()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodingProjects/diffusion-aware-graph-compression/src/dagc/sparsifiers/gnn/train.py:199\u001b[39m, in \u001b[36mtrain_gnn_sparsifier_on_dataset\u001b[39m\u001b[34m(train_dir, val_dir, keep_ratio, num_steps, hidden_dim, num_layers, edge_mlp_hidden_dim, num_epochs, learning_rate, lambda_sparsity, device, print_every, checkpoint_path)\u001b[39m\n\u001b[32m    196\u001b[39m train_sparsity_loss = train_sparsity_sum / denom\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m val_loss, val_rw_loss, val_sparsity_loss = \u001b[43m_eval_on_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlambda_sparsity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlambda_sparsity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdev\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m history[\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m].append(epoch)\n\u001b[32m    209\u001b[39m history[\u001b[33m\"\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m\"\u001b[39m].append(train_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodingProjects/diffusion-aware-graph-compression/src/dagc/sparsifiers/gnn/train.py:57\u001b[39m, in \u001b[36m_eval_on_dataset\u001b[39m\u001b[34m(model, dataset, keep_ratio, num_steps, lambda_sparsity, device)\u001b[39m\n\u001b[32m     48\u001b[39m edge_index = sample.edge_index.to(device)\n\u001b[32m     50\u001b[39m T_orig = compute_transition_matrix_from_graph(\n\u001b[32m     51\u001b[39m     G,\n\u001b[32m     52\u001b[39m     device=device,\n\u001b[32m     53\u001b[39m     weight_attr=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     54\u001b[39m     num_steps=num_steps,\n\u001b[32m     55\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m total_loss, comps = random_walk_preservation_loss(\n\u001b[32m     60\u001b[39m     G=G,\n\u001b[32m     61\u001b[39m     edge_probs=out.edge_probs,\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m     return_components=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     68\u001b[39m )\n\u001b[32m     70\u001b[39m total_loss_sum += \u001b[38;5;28mfloat\u001b[39m(total_loss.item())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodingProjects/diffusion-aware-graph-compression/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodingProjects/diffusion-aware-graph-compression/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodingProjects/diffusion-aware-graph-compression/src/dagc/sparsifiers/gnn/gnn_sparsifier.py:54\u001b[39m, in \u001b[36mGNNSparsifier.forward\u001b[39m\u001b[34m(self, x, edge_index)\u001b[39m\n\u001b[32m     50\u001b[39m h_src = H[src]  \u001b[38;5;66;03m# [num_edges_dir, hidden_dim]\u001b[39;00m\n\u001b[32m     51\u001b[39m h_dst = H[dst]  \u001b[38;5;66;03m# [num_edges_dir, hidden_dim]\u001b[39;00m\n\u001b[32m     53\u001b[39m edge_feat = torch.cat(\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     [h_src, h_dst, h_src * h_dst, \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_src\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_dst\u001b[49m\u001b[43m)\u001b[49m],\n\u001b[32m     55\u001b[39m     dim=-\u001b[32m1\u001b[39m,\n\u001b[32m     56\u001b[39m )  \u001b[38;5;66;03m# [num_edges_dir, 4 * hidden_dim]\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Step 3) Edge logits + probabilities\u001b[39;00m\n\u001b[32m     59\u001b[39m edge_logits = \u001b[38;5;28mself\u001b[39m.edge_mlp(edge_feat).squeeze(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# [num_edges_dir]\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ckpt_path = \"results/checkpoints/gnn_rw_k1_keep0.8_num_steps_2.pt\"\n",
    "model, history = train_gnn_sparsifier_on_dataset(train_dir=\"../data/synthetic_graphs/ba/train\", \n",
    "                                                 val_dir=\"../data/synthetic_graphs/ba/val\",\n",
    "                                                 keep_ratio=0.8, \n",
    "                                                 num_steps=2, \n",
    "                                                 num_epochs=15, \n",
    "                                                 learning_rate=1e-3, \n",
    "                                                 lambda_sparsity=1.0,\n",
    "                                                 device=\"cpu\", \n",
    "                                                 print_every=1, \n",
    "                                                 checkpoint_path=ckpt_path, \n",
    "                                                 )\n",
    "epochs = history[\"epoch\"] \n",
    "plt.figure()\n",
    "plt.plot(epochs, history[\"train_loss\"], label=\"train\") \n",
    "plt.plot(epochs, history[\"val_loss\"], label=\"val\") \n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"RW + sparsity loss over epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06fec05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Using device: cpu\n",
      "[train] Loaded 120 train graphs and 40 val graphs\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n",
      "Multiplying for step 2...\n",
      "Multiplying for step 3...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m ckpt_path = \u001b[33m\"\u001b[39m\u001b[33mresults/checkpoints/gnn_rw_k1_keep0.8_num_steps_3.pt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model, history = \u001b[43mtrain_gnn_sparsifier_on_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/synthetic_graphs/ba/train\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mval_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/synthetic_graphs/ba/val\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mkeep_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mlambda_sparsity\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m epochs = history[\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m] \n\u001b[32m     14\u001b[39m plt.figure()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodingProjects/diffusion-aware-graph-compression/src/dagc/sparsifiers/gnn/train.py:173\u001b[39m, in \u001b[36mtrain_gnn_sparsifier_on_dataset\u001b[39m\u001b[34m(train_dir, val_dir, keep_ratio, num_steps, hidden_dim, num_layers, edge_mlp_hidden_dim, num_epochs, learning_rate, lambda_sparsity, device, print_every, checkpoint_path)\u001b[39m\n\u001b[32m    170\u001b[39m optimizer.zero_grad()\n\u001b[32m    171\u001b[39m out = model(x, edge_index)\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m loss, comps = \u001b[43mrandom_walk_preservation_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mG\u001b[49m\u001b[43m=\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43medge_probs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m    \u001b[49m\u001b[43mT_orig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mT_orig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlambda_sparsity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlambda_sparsity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_components\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m avg_prob_sum += \u001b[38;5;28mfloat\u001b[39m(out.edge_probs.mean().detach().cpu())\n\u001b[32m    185\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodingProjects/diffusion-aware-graph-compression/src/dagc/sparsifiers/gnn/losses.py:29\u001b[39m, in \u001b[36mrandom_walk_preservation_loss\u001b[39m\u001b[34m(G, edge_probs, edge_index, T_orig, keep_ratio, lambda_sparsity, num_steps, return_components)\u001b[39m\n\u001b[32m     26\u001b[39m G_tilde = build_temp_weighted_graph_from_probs(G, edge_probs, edge_index)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# 2) Compute k-step transition matrix T_tilde\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m T_tilde = \u001b[43mcompute_transition_matrix_from_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mG_tilde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_attr\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# 3) Random-walk preservation term: ||T_tilde - T_orig||_F^2\u001b[39;00m\n\u001b[32m     37\u001b[39m diff = T_tilde - T_orig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodingProjects/diffusion-aware-graph-compression/src/dagc/sparsifiers/gnn/utils.py:45\u001b[39m, in \u001b[36mcompute_transition_matrix_from_graph\u001b[39m\u001b[34m(G, device, weight_attr, num_steps)\u001b[39m\n\u001b[32m     43\u001b[39m         w = \u001b[38;5;28mfloat\u001b[39m(data.get(weight_attr, \u001b[32m1.0\u001b[39m))\n\u001b[32m     44\u001b[39m     T[u, v] = w\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     T[v, u] = w\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Row-normalize to get 1-step random walk matrix\u001b[39;00m\n\u001b[32m     48\u001b[39m row_sums = T.sum(dim=\u001b[32m1\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m) + \u001b[32m1e-8\u001b[39m  \u001b[38;5;66;03m# [n,1]\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ckpt_path = \"results/checkpoints/gnn_rw_k1_keep0.8_num_steps_3.pt\"\n",
    "model, history = train_gnn_sparsifier_on_dataset(train_dir=\"../data/synthetic_graphs/ba/train\", \n",
    "                                                 val_dir=\"../data/synthetic_graphs/ba/val\",\n",
    "                                                 keep_ratio=0.8, \n",
    "                                                 num_steps=3, \n",
    "                                                 num_epochs=15, \n",
    "                                                 learning_rate=1e-3, \n",
    "                                                 lambda_sparsity=1.0,\n",
    "                                                 device=\"cpu\", \n",
    "                                                 print_every=1, \n",
    "                                                 checkpoint_path=ckpt_path, \n",
    "                                                 )\n",
    "epochs = history[\"epoch\"] \n",
    "plt.figure()\n",
    "plt.plot(epochs, history[\"train_loss\"], label=\"train\") \n",
    "plt.plot(epochs, history[\"val_loss\"], label=\"val\") \n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"RW + sparsity loss over epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b97c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
